{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1 : What is Simple Linear Regression (SLR)? Explain its purpose.\n",
        "- Simple Linear Regression (SLR) is one of the most fundamental and widely used techniques in statistics and machine learning. It is a supervised learning algorithm that is used to understand and model the relationship between two variables: one independent variable (predictor) and one dependent variable (response).\n",
        "\n",
        "In Simple Linear Regression, we assume that the relationship between the independent variable and the dependent variable can be represented by a straight line. This linear relationship helps us describe how changes in the independent variable influence the dependent variable.\n",
        "\n",
        "Mathematically, Simple Linear Regression is represented by the equation:\n",
        "\n",
        "y=Œ≤0‚Äã+Œ≤1‚Äãx+Œµ\n",
        "\n",
        "Where:\n",
        "\n",
        "y is the dependent variable (the variable we want to predict)\n",
        "\n",
        "x is the independent variable (the variable used for prediction)\n",
        "\n",
        "ùõΩ\n",
        "0\n",
        "is the intercept, which represents the value of\n",
        "y when\n",
        "x=0\n",
        "\n",
        "ùõΩ\n",
        "1\n",
        "is the slope, which indicates the rate of change of\n",
        "y with respect to\n",
        "x\n",
        "\n",
        "ùúÄ\n",
        "is the error term, which captures the effect of factors not included in the model\n",
        "\n",
        "The main idea of Simple Linear Regression is to find the best-fitting straight line that minimizes the difference between the actual observed values and the values predicted by the model. This is usually achieved using the Least Squares Method, where the sum of squared errors is minimized.\n",
        "\n",
        "Purpose of Simple Linear Regression\n",
        "\n",
        "The purpose of Simple Linear Regression can be explained from multiple perspectives:\n",
        "\n",
        "- Understanding Relationship Between Variables:\n",
        "SLR helps in identifying whether there is a relationship between two variables and understanding the nature of that relationship (positive or negative). For example, it can be used to study how study hours affect exam scores.\n",
        "\n",
        "- Prediction of Future Values:\n",
        "Once the relationship is established, Simple Linear Regression can be used to predict the value of the dependent variable for a given value of the independent variable. For instance, predicting house prices based on area.\n",
        "\n",
        "- Quantifying Impact:\n",
        "The slope (\n",
        "ùõΩ\n",
        "1\n",
        ") provides a numerical value that explains how much the dependent variable changes when the independent variable changes by one unit. This helps in decision-making and analysis.\n",
        "\n",
        "- Trend Analysis:\n",
        "SLR is useful in analyzing trends over time, such as sales growth, population increase, or temperature changes.\n",
        "\n",
        "- Foundation for Advanced Models:\n",
        "Simple Linear Regression forms the basis for more advanced regression techniques like Multiple Linear Regression, Polynomial Regression, and Regularized Regression (Ridge, Lasso).\n",
        "\n",
        "Question 2: What are the key assumptions of Simple Linear Regression?\n",
        "- 1. Linearity\n",
        "\n",
        "The most important assumption of Simple Linear Regression is that there exists a linear relationship between the independent variable and the dependent variable. This means that the change in the dependent variable is proportional to the change in the independent variable.\n",
        "\n",
        "If the true relationship between variables is non-linear, a simple linear model will fail to capture the pattern accurately, leading to poor predictions.\n",
        "\n",
        "Example:\n",
        "If exam scores increase consistently as study hours increase, the relationship can be considered linear.\n",
        "\n",
        "- 2. Independence of Errors\n",
        "\n",
        "This assumption states that the error terms (residuals) are independent of each other. In other words, the error for one observation should not influence the error for another observation.\n",
        "\n",
        "Violation of this assumption commonly occurs in time-series data, where past values can affect future values.\n",
        "\n",
        "Why it matters:\n",
        "If errors are correlated, the model may give misleading results and unreliable statistical tests.\n",
        "\n",
        "- 3. Homoscedasticity (Constant Variance of Errors)\n",
        "\n",
        "Homoscedasticity means that the variance of the error terms remains constant across all levels of the independent variable.\n",
        "\n",
        "If the spread of residuals increases or decreases with the value of the independent variable, the data is said to have heteroscedasticity, which can reduce the efficiency of the model.\n",
        "\n",
        "Example:\n",
        "Prediction errors for low and high values of\n",
        "x should have roughly the same spread.\n",
        "\n",
        "- 4. Normality of Errors\n",
        "\n",
        "This assumption states that the error terms are normally distributed with a mean of zero. While the regression model can still work without perfect normality, this assumption is important for:\n",
        "\n",
        "Confidence intervals\n",
        "\n",
        "Hypothesis testing\n",
        "\n",
        "Statistical significance of coefficients\n",
        "\n",
        "Note:\n",
        "Normality is more critical for inference than for prediction.\n",
        "\n",
        "- 5. No Multicollinearity (Trivial in SLR)\n",
        "\n",
        "In Simple Linear Regression, only one independent variable is used, so multicollinearity is not a practical concern. However, conceptually, it assumes that the independent variable is not influenced by another hidden variable that strongly affects the dependent variable.\n",
        "\n",
        "- 6. Zero Mean of Errors\n",
        "\n",
        "The average value of the error term is assumed to be zero. This means the model does not consistently overestimate or underestimate the dependent variable.\n",
        "\n",
        "- 7. No Extreme Outliers\n",
        "\n",
        "Although not always listed as a formal assumption, Simple Linear Regression assumes that the data does not contain extreme outliers that can disproportionately influence the regression line.\n",
        "\n",
        "Outliers can distort the slope and intercept, leading to misleading conclusions.\n",
        "\n",
        "Question 3: Write the mathematical equation for a simple linear regression model and explain each term.\n",
        "- The mathematical equation of a Simple Linear Regression model describes the relationship between one independent variable and one dependent variable using a straight line. This equation helps in understanding how changes in the independent variable affect the dependent variable.\n",
        "\n",
        "The standard equation of a Simple Linear Regression model is:\n",
        "\n",
        "ùë¶=\n",
        "ùõΩ\n",
        "0\n",
        "+\n",
        "ùõΩ\n",
        "1\n",
        "ùë•\n",
        "+\n",
        "ùúÄ\n",
        "1. Dependent Variable (\n",
        "y)\n",
        "\n",
        "The dependent variable represents the output or response that the model aims to predict or explain. Its value depends on the independent variable.\n",
        "\n",
        "Example:\n",
        "\n",
        "House price depending on area\n",
        "\n",
        "Marks obtained depending on hours of study\n",
        "\n",
        " 2. Independent Variable (\n",
        "x)\n",
        "\n",
        "The independent variable is the input or predictor used to estimate the value of the dependent variable. In Simple Linear Regression, only one independent variable is involved.\n",
        "\n",
        "3. Intercept (\n",
        "ùõΩ\n",
        "0\n",
        ")\n",
        "\n",
        "The intercept is the value of the dependent variable when the independent variable\n",
        "x is equal to zero. It represents the point where the regression line crosses the y-axis.\n",
        "\n",
        "Although in some real-life cases\n",
        "x=0 may not be meaningful, the intercept is important for constructing the regression line.\n",
        "\n",
        "4. Slope (\n",
        "ùõΩ\n",
        "1\n",
        ")\n",
        "\n",
        "The slope indicates the rate of change in the dependent variable for a one-unit change in the independent variable. It shows both the direction and strength of the relationship.\n",
        "\n",
        "A positive slope means\n",
        "y increases as\n",
        "x increases\n",
        "\n",
        "A negative slope means\n",
        "y decreases as\n",
        "x increases\n",
        "\n",
        "Question 4: Provide a real-world example where simple linear regression can be applied.\n",
        "- A common and practical real-world example where Simple Linear Regression can be applied is in predicting house prices based on the size (area) of the house.\n",
        "Example: House Price Prediction\n",
        "\n",
        "In the real estate industry, property prices are often influenced by several factors. However, to understand the basic relationship between two variables, Simple Linear Regression can be effectively used by considering:\n",
        "\n",
        "Independent Variable (x): Area of the house (in square feet)\n",
        "\n",
        "Dependent Variable (y): Price of the house (in lakhs or millions)\n",
        "\n",
        "The assumption here is that, in general, as the area of a house increases, its price also increases in a roughly linear manner.\n",
        "\n",
        "Regression Model\n",
        "\n",
        "Using Simple Linear Regression, the relationship between house area and price can be represented as:\n",
        "\n",
        "House Price=\n",
        "ùõΩ\n",
        "0\n",
        "+\n",
        "ùõΩ\n",
        "1\n",
        "√ó\n",
        "Area\n",
        "+\n",
        "ùúÄ\n",
        "Where:\n",
        "ùõΩ\n",
        "0\n",
        "represents the base price of a house\n",
        "\n",
        "ùõΩ\n",
        "1\n",
        "indicates how much the house price increases for each additional square foot\n",
        "\n",
        "Œµ captures variations due to location, amenities, market conditions, etc.\n",
        "\n",
        "- Practical Use:\n",
        "\n",
        "Once the model is trained using historical data:\n",
        "\n",
        "Real estate companies can estimate property prices for new listings\n",
        "\n",
        "Buyers can evaluate whether a quoted price is reasonable\n",
        "\n",
        "Builders can plan pricing strategies based on expected returns\n",
        "\n",
        "For example, if the regression model shows that house prices increase by ‚Çπ3,000 per square foot, then a 1,000 sq. ft. house would be priced approximately ‚Çπ30 lakh higher than a 0 sq. ft. baseline.\n",
        "\n",
        "- Why Simple Linear Regression is Suitable:\n",
        "\n",
        "Only one major factor (area) is considered\n",
        "\n",
        "The relationship is easy to understand and interpret\n",
        "\n",
        "Results can be clearly explained to non-technical stakeholders\n",
        "\n",
        "- Other Real-World Examples:\n",
        "\n",
        "Simple Linear Regression can also be applied in:\n",
        "\n",
        "Predicting exam scores based on study hours\n",
        "\n",
        "Estimating sales revenue based on advertising spend\n",
        "\n",
        "Forecasting electricity consumption based on temperature\n",
        "\n",
        "Question 5: What is the method of least squares in linear regression?\n",
        "- The method of least squares is a mathematical approach used in linear regression to find the best-fitting regression line for a given set of data points. The main objective of this method is to estimate the values of the regression coefficients in such a way that the predicted values are as close as possible to the actual observed values.\n",
        "\n",
        "In Simple Linear Regression, the method of least squares is used to determine the optimal values of the intercept and slope of the regression line.\n",
        "Concept Behind Least Squares\n",
        "\n",
        "When a regression line is drawn, it does not usually pass through all data points exactly. The difference between the actual value and the predicted value is called the residual or error.\n",
        "\n",
        "Residual\n",
        "=yi‚Äã‚àíy^‚Äãi‚Äã\n",
        "\n",
        "The method of least squares minimizes the sum of the squares of these residuals. Squaring the errors ensures that:\n",
        "\n",
        "Positive and negative errors do not cancel each other out\n",
        "\n",
        "Larger errors are penalized more heavily\n",
        "\n",
        "The method of least squares minimizes the sum of the squares of these residuals. Squaring the errors ensures that:\n",
        "\n",
        "Positive and negative errors do not cancel each other out\n",
        "\n",
        "Larger errors are penalized more heavily\n",
        "\n",
        "Mathematically, the objective is to minimize:\n",
        "\n",
        "i=1‚àën‚Äã(yi‚Äã‚àíy^‚Äãi‚Äã)2\n",
        "\n",
        "Why ‚ÄúLeast Squares‚Äù?\n",
        "\n",
        "The name comes from the idea of finding parameter values that produce the smallest possible squared errors between observed and predicted values. The resulting regression line is considered the best fit under this criterion.\n",
        "\n",
        "Estimation of Regression Coefficients\n",
        "\n",
        "For Simple Linear Regression, the regression equation is:\n",
        "\n",
        "ùë¶^\n",
        "\n",
        "=\n",
        "ùõΩ\n",
        "0\n",
        "+\n",
        "ùõΩ\n",
        "1\n",
        "ùë•\n",
        "\n",
        "Using the least squares method, the estimates of the slope (\n",
        "ùõΩ\n",
        "1\n",
        ") and intercept (\n",
        "ùõΩ\n",
        "0\n",
        ") are calculated as:\n",
        "\n",
        "\n",
        "Œ≤1‚Äã=‚àë(xi‚Äã‚àíxÀâ)2‚àë(xi‚Äã‚àíxÀâ)(yi‚Äã‚àíyÀâ‚Äã)\n",
        "\n",
        "\n",
        "- Intuition Behind the Method:\n",
        "\n",
        "The least squares method adjusts the regression line so that:\n",
        "\n",
        "The total vertical distance between data points and the line is minimized\n",
        "\n",
        "The line balances errors above and below it\n",
        "\n",
        "Predictions are as accurate as possible on average\n",
        "\n",
        "This makes the method both statistically sound and computationally efficient.\n",
        "\n",
        "- Advantages of Least Squares Method:-\n",
        "\n",
        "Simple and easy to implement\n",
        "\n",
        "Provides unique and optimal solutions under linear assumptions\n",
        "\n",
        "Widely used and well-understood in statistics and machine learning\n",
        "\n",
        "- Limitations:\n",
        "\n",
        "Sensitive to outliers, as squaring large errors increases their impact\n",
        "\n",
        "Assumes a linear relationship between variables\n",
        "\n",
        "Performs poorly when regression assumptions are violated‚Äã"
      ],
      "metadata": {
        "id": "JYIAyBjb5KTW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: What is Logistic Regression? How does it differ from Linear Regression?\n",
        "- Logistic Regression is a supervised machine learning algorithm used primarily for classification problems, especially when the target variable is binary in nature. Despite having the word ‚Äúregression‚Äù in its name, logistic regression is actually a classification technique rather than a regression technique.\n",
        "\n",
        "It is used to predict the probability that a given input belongs to a particular class, such as yes/no, true/false, 0/1, etc.\n",
        "\n",
        "What is Logistic Regression?\n",
        "\n",
        "In Logistic Regression, the output is not a continuous value. Instead, it is a probability value between 0 and 1, which is then converted into a class label using a threshold (commonly 0.5).\n",
        "\n",
        "The logistic regression model uses the sigmoid (logistic) function to map any real-valued number into the range (0, 1):\n",
        "\n",
        "P(y=1)=1/1+e res to power ‚àíz1‚Äã\n",
        "\n",
        "where:\n",
        "z=Œ≤0‚Äã+Œ≤1‚Äãx\n",
        "\n",
        "his transformation ensures that the predicted output is always a valid probability.\n",
        "\n",
        "Example:\n",
        "Predicting whether an email is spam or not spam, or whether a student will pass or fail an exam.\n",
        "\n",
        "What is Linear Regression?\n",
        "\n",
        "Linear Regression is a supervised learning algorithm used for predicting continuous numerical values. It assumes a linear relationship between the independent variable(s) and the dependent variable.\n",
        "\n",
        "The output of linear regression can take any real value, positive or negative.\n",
        "\n",
        "ùë¶=\n",
        "ùõΩ\n",
        "0\n",
        "+\n",
        "ùõΩ\n",
        "1\n",
        "ùë•\n",
        "+\n",
        "ùúÄ\n",
        "\n",
        "Example:\n",
        "Predicting house prices, sales revenue, or temperature.\n",
        "\n",
        "| Feature           | Linear Regression        | Logistic Regression          |\n",
        "| ----------------- | ------------------------ | ---------------------------- |\n",
        "| Type of Problem   | Regression               | Classification               |\n",
        "| Output            | Continuous values        | Probability (0 to 1)         |\n",
        "| Target Variable   | Numerical                | Categorical (usually binary) |\n",
        "| Function Used     | Linear function          | Sigmoid (logistic) function  |\n",
        "| Prediction Range  | (-\\infty) to (+\\infty)   | 0 to 1                       |\n",
        "| Loss Function     | Mean Squared Error (MSE) | Log Loss (Cross-Entropy)     |\n",
        "| Decision Boundary | Not applicable           | Yes                          |\n",
        "| Interpretation    | Predicts exact value     | Predicts class probability   |\n",
        "\n",
        "\n",
        "- Why Logistic Regression is Needed\n",
        "\n",
        "Linear Regression is not suitable for classification because:\n",
        "\n",
        "It can predict values outside the range [0, 1]\n",
        "\n",
        "It does not provide probabilistic interpretation\n",
        "\n",
        "It performs poorly for class separation\n",
        "\n",
        "Logistic Regression overcomes these limitations by applying a non-linear transformation (sigmoid function).\n",
        "\n",
        "- Real-World Example\n",
        "\n",
        "Linear Regression: Predicting the salary based on years of experience\n",
        "\n",
        "Logistic Regression: Predicting whether a customer will buy a product or not\n",
        "\n",
        "Question 7: Name and briefly describe three common evaluation metrics for regression models.\n",
        "- After building a regression model, it is very important to evaluate how well the model is performing. Evaluation metrics help us measure the difference between the actual values and the values predicted by the regression model. These metrics provide insight into the accuracy, reliability, and overall effectiveness of the model.\n",
        "\n",
        "1. Mean Absolute Error (MAE)\n",
        "\n",
        "Mean Absolute Error measures the average magnitude of errors between the actual and predicted values, without considering their direction.\n",
        "\n",
        "MAE=i=1 to N summision of |y actual - y pred|*2\n",
        "\n",
        "Explanation:\n",
        "\n",
        "It calculates the absolute difference between actual and predicted values.\n",
        "\n",
        "All errors are treated equally.\n",
        "\n",
        "The result is easy to interpret because it is in the same unit as the target variable.\n",
        "\n",
        "Use Case:\n",
        "MAE is useful when we want a simple and robust measure of average error, especially when outliers are not a major concern.\n",
        "\n",
        "2. Mean Squared Error (MSE)\n",
        "\n",
        "Mean Squared Error measures the average of the squared differences between actual and predicted values.\n",
        "\n",
        "MSE=1\\N 1 to N summision of |y actual - y pred|*2\n",
        "\n",
        "Explanation:\n",
        "\n",
        "Squaring the errors penalizes larger errors more heavily.\n",
        "\n",
        "It is sensitive to outliers.\n",
        "\n",
        "Widely used in optimization during model training.\n",
        "\n",
        "Use Case:\n",
        "MSE is preferred when large errors are particularly undesirable and need stronger penalization.\n",
        "\n",
        "3. R-squared (Coefficient of Determination)\n",
        "\n",
        "R-squared measures how well the regression model explains the variation in the dependent variable.\n",
        "\n",
        "R*2= 1- RSS\\TSS or SSR\\TSS\n",
        "\n",
        "Explanation:\n",
        "\n",
        "Values range from 0 to 1 (sometimes negative for poor models).\n",
        "\n",
        "A higher R¬≤ value indicates a better fit.\n",
        "\n",
        "It explains the proportion of variance explained by the model.\n",
        "\n",
        "Use Case:\n",
        "R-squared is useful for understanding the overall goodness of fit of the regression model.\n",
        "\n",
        "Question 8: What is the purpose of the R-squared metric in regression analysis?\n",
        "- The R-squared metric, also known as the Coefficient of Determination, is one of the most commonly used evaluation measures in regression analysis. Its primary purpose is to explain how well a regression model fits the given data by measuring the proportion of variance in the dependent variable that is explained by the independent variable(s).\n",
        "\n",
        "In simple terms, R-squared tells us how much of the variation in the output can be explained by the input features used in the model.\n",
        "\n",
        "Understanding R-squared\n",
        "\n",
        "Mathematically, R-squared is defined as:\n",
        "\n",
        "R*2= 1- RSS\\TSS\n",
        "\n",
        "The value of R-squared usually lies between 0 and 1:\n",
        "\n",
        "R¬≤ = 0 ‚Üí The model explains none of the variation\n",
        "\n",
        "R¬≤ = 1 ‚Üí The model explains all the variation\n",
        "\n",
        "Purpose of R-squared\n",
        "\n",
        "Measures Goodness of Fit\n",
        "R-squared indicates how well the regression line fits the observed data. A higher R¬≤ value generally suggests that the model captures the underlying pattern effectively.\n",
        "\n",
        "Explains Variance in Data\n",
        "It quantifies the percentage of variability in the dependent variable that is explained by the independent variable(s).\n",
        "\n",
        "Example:\n",
        "An R¬≤ value of 0.75 means that 75% of the variation in the target variable is explained by the model.\n",
        "\n",
        "Model Comparison\n",
        "R-squared helps compare different regression models built on the same dataset. The model with a higher R¬≤ is usually considered better, provided overfitting is avoided.\n",
        "\n",
        "Interpretability\n",
        "Unlike error-based metrics, R-squared provides an intuitive explanation that is easy for non-technical stakeholders to understand.\n",
        "\n",
        "Limitations of R-squared\n",
        "\n",
        "A high R¬≤ does not guarantee that the model is correct or meaningful\n",
        "\n",
        "It does not indicate causation\n",
        "\n",
        "It can increase when unnecessary variables are added (in multiple regression)\n",
        "\n",
        "It does not measure prediction accuracy directly\n",
        "\n"
      ],
      "metadata": {
        "id": "hu9oyMxaEVMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 9: Write Python code to fit a simple linear regression model using scikit-learn and print the slope and intercept.\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Sample dataset\n",
        "# Independent variable (X)\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
        "\n",
        "# Dependent variable (y)\n",
        "y = np.array([2, 4, 6, 8, 10])\n",
        "\n",
        "# Create and train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get slope and intercept\n",
        "slope = model.coef_[0]\n",
        "intercept = model.intercept_\n",
        "\n",
        "# Print results\n",
        "print(\"Slope (Coefficient):\", slope)\n",
        "print(\"Intercept:\", intercept)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMJcU-x6HCaT",
        "outputId": "9ae20083-bf9e-41ce-b125-5c6fe2574bcc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (Coefficient): 2.0\n",
            "Intercept: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: How do you interpret the coefficients in a simple linear regression model?\n",
        "- In a Simple Linear Regression (SLR) model, the coefficients play a crucial role in explaining the relationship between the independent variable and the dependent variable. Interpreting these coefficients correctly helps us understand how changes in the input variable influence the output variable in real-world terms.\n",
        "\n",
        "The general equation of a simple linear regression model is:\n",
        "\n",
        "ùë¶=\n",
        "ùõΩ\n",
        "0\n",
        "+\n",
        "ùõΩ\n",
        "1\n",
        "ùë•\n",
        "+\n",
        "ùúÄ\n",
        "\n",
        "\n",
        "Here, the model contains two main coefficients: the intercept (\n",
        "ùõΩ\n",
        "0\n",
        ") and the slope (\n",
        "ùõΩ\n",
        "1\n",
        "). Each of these has a specific interpretation.\n",
        "\n",
        "\n",
        "1. Interpretation of the Intercept (\n",
        "ùõΩ\n",
        "0‚Äã\n",
        ")\n",
        "\n",
        "The intercept represents the expected value of the dependent variable when the independent variable is zero.\n",
        "\n",
        "Meaning:\n",
        "\n",
        "It is the point where the regression line crosses the y-axis.\n",
        "\n",
        "It provides a baseline or starting value for the model.\n",
        "\n",
        "Example:\n",
        "If we have a model that predicts exam marks based on hours of study and the intercept is 20, it means that a student is expected to score 20 marks even if they study for 0 hours.\n",
        "\n",
        "Important Note:\n",
        "In some real-life situations,\n",
        "x=0 may not be meaningful (e.g., predicting salary when years of experience are zero). Even in such cases, the intercept is mathematically necessary to define the regression line.\n",
        "\n",
        "2. Interpretation of the Slope (\n",
        "ùõΩ\n",
        "1\n",
        ")\n",
        "\n",
        "The slope represents the average change in the dependent variable for a one-unit increase in the independent variable.\n",
        "\n",
        "Meaning:\n",
        "\n",
        "It indicates the direction and strength of the relationship.\n",
        "\n",
        "A positive slope shows a direct relationship.\n",
        "\n",
        "A negative slope shows an inverse relationship.\n",
        "\n",
        "Example:\n",
        "If the slope is 5, it means that for every additional hour of study, the student‚Äôs marks increase by 5 points on average.\n",
        "\n",
        "3. Practical Interpretation\n",
        "\n",
        "The slope helps in decision-making by quantifying impact.\n",
        "\n",
        "It allows us to predict future values.\n",
        "\n",
        "It makes the model easy to explain to non-technical audiences.\n",
        "\n",
        "4. Role of the Error Term\n",
        "\n",
        "Although not a coefficient, the error term represents the portion of the dependent variable that cannot be explained by the model. It reminds us that regression coefficients describe average trends, not exact outcomes."
      ],
      "metadata": {
        "id": "3K99lQSnHSxM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "59w-b6pfHvGH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}